# Speech-Emotion-Recognition

# The.ipynb and.py files in this repo are functionally equivalent; unless otherwise specified, use the.ipynb file as the default.

This project was developed and implemented as part of the course Audio Processing and Indexing hosted by LIACS at Leiden University in the academic year 2022-2023.

This notebook contains three functioning parts.
1. A frequency spectrogram merging section that illustrate the merging of spectrograms regarding different emotions.
2. A MFCC extraction section to create MFCC spectrograms used as input in model training.
3. A CNN network section that contains a model that learns from MFCC inputs and achieves an accuracy of roughly 60%.
